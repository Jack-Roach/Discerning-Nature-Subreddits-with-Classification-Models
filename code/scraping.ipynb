{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping subreddit post data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "#panda character display limit\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Subreddit Posts using the Pushshift API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Scraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(subreddit,post_amount):\n",
    "    f\"\"\"\n",
    "    Arguments:\n",
    "        subreddit: subreddit to retrieve posts from\n",
    "        post_amount: total number of posts to take from r/{subreddit}\n",
    "    Output: \n",
    "        pandas.core.frame.DataFrame containing {post_amount} rows of data with each row representing a unique reddit post\n",
    "        and each column storing a different post attribute\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://api.pushshift.io/reddit/search/submission' # Base url for pushshift\n",
    "    print(f'retrieving {post_amount} recent posts from r/{subreddit}') # Message confirming parameters\n",
    "    \n",
    "    timestamp = 1651204800 #April 29th, 2022 at 12am\n",
    "    pulled_data = pd.DataFrame()\n",
    "    for i in range(post_amount//100):\n",
    "        parameters = {\n",
    "            'subreddit':subreddit,\n",
    "            'size': 100,\n",
    "            'before':timestamp\n",
    "        }\n",
    "        res = requests.get(url, params=parameters)\n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        pulled_data = pd.concat([pulled_data,pd.DataFrame(posts)])#adds batch of posts to DataFrame\n",
    "        timestamp = posts[-1]['created_utc'] #references oldest post in the batch of 100 to draw the next batch before it\n",
    "        time.sleep(60) #pulling 100 posts per minute\n",
    "    return pulled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the Scraping Function on r/natureisfuckinglit and r/natureismetal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code block is commented out as it will take 1 hour and 40 minutes to run. The data has already been collected and stored in subreddit_data.csv in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving 5000 recent posts from r/natureisfuckinglit\n",
      "retrieving 5000 recent posts from r/natureismetal\n"
     ]
    }
   ],
   "source": [
    "# Each subreddit has its own dataframe\n",
    "natureisfuckinglit = get_posts('natureisfuckinglit',5000)\n",
    "natureismetal = get_posts('natureismetal',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 79)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natureisfuckinglit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 83)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natureismetal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning irrelevant information from the datatframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NatureIsFuckingLit</td>\n",
       "      <td></td>\n",
       "      <td>A centipede that lives in my house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NatureIsFuckingLit</td>\n",
       "      <td></td>\n",
       "      <td>The Most Beautiful and Naturally White Animals in the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NatureIsFuckingLit</td>\n",
       "      <td></td>\n",
       "      <td>üî• kissing camels, Desert, Algeria üê™</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit selftext  \\\n",
       "0  NatureIsFuckingLit            \n",
       "1  NatureIsFuckingLit            \n",
       "2  NatureIsFuckingLit            \n",
       "\n",
       "                                                         title  \n",
       "0                           A centipede that lives in my house  \n",
       "1  The Most Beautiful and Naturally White Animals in the World  \n",
       "2                          üî• kissing camels, Desert, Algeria üê™  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natureisfuckinglit = natureisfuckinglit[['subreddit', 'selftext', 'title']].reset_index().drop(columns='index')\n",
    "natureisfuckinglit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>natureismetal</td>\n",
       "      <td></td>\n",
       "      <td>Suddenly mini golf wasn‚Äôt so fun anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natureismetal</td>\n",
       "      <td></td>\n",
       "      <td>Crow dissects baby bird in front of parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natureismetal</td>\n",
       "      <td></td>\n",
       "      <td>Last stand for lone wolf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit selftext                                        title\n",
       "0  natureismetal              Suddenly mini golf wasn‚Äôt so fun anymore\n",
       "1  natureismetal           Crow dissects baby bird in front of parents\n",
       "2  natureismetal                              Last stand for lone wolf"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natureismetal = natureismetal[['subreddit', 'selftext', 'title']].reset_index().drop(columns='index')\n",
    "natureismetal.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the dataframes vertically into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([natureismetal,natureisfuckinglit],ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9997, 3)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "natureismetal         5000\n",
       "NatureIsFuckingLit    4997\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        9695\n",
       "[removed]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                185\n",
       "[deleted]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                113\n",
       "Hey everyone!  Today is the release date of Marvel's next movie *Spider-Man: No Way Home*, and thus we've added pretty extensive spoiler code to our auto-mod, so we're hoping to prevent anything from being ruined for anyone who plans to and hasn't yet seen the movie.  This will be in place for one week, or until December 24 (ish).  \\n\\nOf course, we can't catch everything, so we've also included another command that if anyone simply responds to such a comment with \"Spoiler\", it'll create a notification for us to check it out and take any necessary actions.  This specific code will be removed December 20(ish).  \\n\\nFun Fact: I was added to the mod team because I had noticed this and /r/NatureIsFuckingLit being overrun by spam spoiler bots for *Avengers: Endgame* and I had already seen it three times in the first 36 hours it was released, and was happy to help them out.  So, this is quite important to me.  \\n\\nGo Spidey!       1\n",
       "Name: selftext, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['selftext'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the contents of the combined DataFrame into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv('../data/subreddit_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
